{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/ANDREWTOLUTAIWO/poor_people_water_consumption/blob/main/PhD%20Thesis%20MLR%20code.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation, Testing and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Training the model\n",
    "def training(x1, y1):\n",
    "    print('TRAINING DATA')\n",
    "    X_train_prediction = model.predict(x1)\n",
    "    #Evaluating the trained model\n",
    "    evaluation(y_train, X_train_prediction)\n",
    "    \n",
    "#Validating the model\n",
    "def validation(x1, y1):\n",
    "    print('VALIDATION DATA')\n",
    "    X_valid_prediction = model.predict(x1)\n",
    "    #Evaluating the validated model\n",
    "    evaluation(y1, X_valid_prediction)\n",
    "\n",
    "#Testing the model\n",
    "def testing(x1, y1):\n",
    "    print('TESTING DATA')\n",
    "    X_test_prediction = model.predict(x1)\n",
    "    #Evaluating the tested model\n",
    "    evaluation(y1, X_test_prediction)\n",
    "    \n",
    "\n",
    "# Predicting with the complete data\n",
    "def complete_prediction(x1, y1):\n",
    "    print('COMPLETE DATA')\n",
    "    X_complete_prediction = model.predict(x1)\n",
    "    evaluation(y, X_complete_prediction)\n",
    "    #Convert to dataframe\n",
    "    pred = pd.DataFrame(X_complete_prediction, columns=['Predicted volume'])\n",
    "    # Join original data table and pred\n",
    "    complete_data = pd.DataFrame(pd.concat([data, pred], axis=1))\n",
    "    #Get first 100 records\n",
    "    data100 = complete_data.iloc[:100]\n",
    "    #print into excel csv file\n",
    "    karu_trained_result = complete_data.to_csv('mararaba_tested_result_MLR.csv')\n",
    "    \n",
    "# Model evaluation with Mean Absolute Error, Root Mean Square Error and Root Meas Square Percentage Error\n",
    "def evaluation(x, y):\n",
    "    import sys\n",
    "    np.set_printoptions(precision=None, threshold=sys.maxsize, edgeitems=7)\n",
    "    mae = np.abs(np.subtract(x, np.asarray(y))).mean()\n",
    "    print('MAE = ', mae)\n",
    "    rmse = math.sqrt(np.square(np.subtract(x, y)).mean())\n",
    "    print('RMSE = ', rmse)\n",
    "    n = (np.subtract(x, x.mean())*np.subtract(y, y.mean())).sum()\n",
    "    d = math.sqrt(np.square(np.subtract(x, x.mean())).sum()*np.square(np.subtract(y, y.mean())).sum())\n",
    "    r2s = np.ceil(np.square(n/d)*100.0)\n",
    "    print('Rsquared =', r2s, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normal Equation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal_equation(X, y): \n",
    "    # X = Coefficient matrix, \n",
    "    # y = observation vector, or the vector of target variable\n",
    "       \n",
    "    from numpy.linalg import inv\n",
    "    import numpy as np\n",
    "    import sys\n",
    "    np.set_printoptions(precision=None, threshold=sys.maxsize, edgeitems=7)\n",
    "    # set bias term to 1 for each sample and concatenate with A  \n",
    "    A = np.c_[np.ones((len(X), 1)), X]\n",
    "    #print(\"Coefficient Matrix, A: \", \"\\n\", A, \"\\n\")    # Print design marix A\n",
    "    # Solution to normal equation  # theta = (A.T * X)^(-1) * A.T * y \n",
    "    A_transpose = A.T  \n",
    "    params = inv(A_transpose.dot(A)).dot(A_transpose).dot(y) \n",
    "    print('Here are the parameters; intercept is first in the list: ',\"\\n\", params, \"\\n\")\n",
    "    # test prediction  \n",
    "    A2 = np.c_[np.ones((len(X), 1)), X]  \n",
    "    prediction = A2.dot(params) \n",
    "    #print(\"Prediction: \", \"\\n\", prediction, \"\\n\")   # Print predictions\n",
    "    #Evaluating the output by calling the function Evaluation\n",
    "    evaluation(y, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Multilinear Regression with Karu Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "MAE =  36.994300786460784\n",
      "RMSE =  100.16007696898056\n",
      "Rsquared = 97.0 \n",
      "\n",
      "VALIDATION DATA\n",
      "MAE =  25.083840010664666\n",
      "RMSE =  56.09338873155501\n",
      "Rsquared = 100.0 \n",
      "\n",
      "TESTING DATA\n",
      "MAE =  25.161171631039924\n",
      "RMSE =  60.89491015593286\n",
      "Rsquared = 99.0 \n",
      "\n",
      "COMPLETE DATA\n",
      "MAE =  34.61994179333909\n",
      "RMSE =  93.33326657186359\n",
      "Rsquared = 98.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split \n",
    "import pandas as pd\n",
    "\n",
    "# Read the file\n",
    "data = pd.read_csv(\"karu_data2.csv\")\n",
    "\n",
    "# Modeling with Predictor Features\n",
    "X = data.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "# Target Feature\n",
    "y = data['Volume']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "# Developing the model with Pipeline that infuses StandardScaler with SDGRegressor\n",
    "model = Pipeline([('scaler', StandardScaler()), ('sgd', SGDRegressor(max_iter=10000, tol=1e-3))])\n",
    "\n",
    "# Fitting the model with training data so that it becomes a trained model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#Testing with Karu_dataset\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Multilinear Regression with Nyanya_Mararaba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "MAE =  86.3140649381325\n",
      "RMSE =  110.1233602538128\n",
      "Rsquared = 52.0 \n",
      "\n",
      "VALIDATION DATA\n",
      "MAE =  82.26976916202494\n",
      "RMSE =  108.54506112310673\n",
      "Rsquared = 59.0 \n",
      "\n",
      "TESTING DATA\n",
      "MAE =  86.0506073025355\n",
      "RMSE =  108.2448527871488\n",
      "Rsquared = 58.0 \n",
      "\n",
      "COMPLETE DATA\n",
      "MAE =  85.88328959696203\n",
      "RMSE =  109.77987713504656\n",
      "Rsquared = 53.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the file\n",
    "data = pd.read_csv(\"Nyanya_Mararaba_test2.csv\")\n",
    "\n",
    "# Modeling with Selected Features\n",
    "X = data.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "y = data['Volume']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Random  Forest with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of bag score =  0.9925276081345047 \n",
      "\n",
      "TRAINING DATA\n",
      "MAE =  19.516570854215935\n",
      "RMSE =  43.7170672276976\n",
      "Rsquared = 100.0 \n",
      "\n",
      "VALIDATION DATA\n",
      "MAE =  31.164480908254223\n",
      "RMSE =  72.81351166753917\n",
      "Rsquared = 99.0 \n",
      "\n",
      "TESTING DATA\n",
      "MAE =  27.875522906090453\n",
      "RMSE =  84.61757019650723\n",
      "Rsquared = 99.0 \n",
      "\n",
      "COMPLETE DATA\n",
      "MAE =  21.517257064807215\n",
      "RMSE =  52.67959415489836\n",
      "Rsquared = 100.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import pandas as pd\n",
    "\n",
    "# Read the file\n",
    "data = pd.read_csv(\"karu_data2.csv\")\n",
    "\n",
    "# Modeling with Selected Features\n",
    "X = data.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "y = data['Volume']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "#Modeling with Random Forest Regressor\n",
    "model = RandomForestRegressor(random_state=42, n_jobs=-1, max_depth=5,\n",
    "                                       n_estimators=100, oob_score=True)\n",
    "\n",
    "#Fitting the model\n",
    "RF_Model = model.fit(X_train, y_train)\n",
    "\n",
    "# checking the oob score\n",
    "print('Out of bag score = ', model.oob_score_, '\\n')\n",
    "\n",
    "\n",
    "# Testing the MLP code\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Random  Forest with Nyanya_Mararaba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "MAE =  63.62965571834088\n",
      "RMSE =  83.07506987237005\n",
      "Rsquared = 73.0 \n",
      "\n",
      "VALIDATION DATA\n",
      "MAE =  74.28269301960167\n",
      "RMSE =  94.24887511750377\n",
      "Rsquared = 69.0 \n",
      "\n",
      "TESTING DATA\n",
      "MAE =  70.33076822337851\n",
      "RMSE =  92.41188364690142\n",
      "Rsquared = 64.0 \n",
      "\n",
      "COMPLETE DATA\n",
      "MAE =  65.36507069897067\n",
      "RMSE =  85.22590250298116\n",
      "Rsquared = 72.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file\n",
    "data = pd.read_csv(\"Nyanya_Mararaba_test2.csv\")\n",
    "\n",
    "# Modeling with Selected Features\n",
    "X = data.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "y = data['Volume']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Support Vector Regression with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "MAE =  275.1868447032512\n",
      "RMSE =  341.1694713758969\n",
      "Rsquared = 98.0 \n",
      "\n",
      "VALIDATION DATA\n",
      "MAE =  263.5476091413879\n",
      "RMSE =  324.55102746680035\n",
      "Rsquared = 99.0 \n",
      "\n",
      "TESTING DATA\n",
      "MAE =  264.5231879104702\n",
      "RMSE =  327.3046465381083\n",
      "Rsquared = 97.0 \n",
      "\n",
      "COMPLETE DATA\n",
      "MAE =  272.956555467787\n",
      "RMSE =  338.1766648759881\n",
      "Rsquared = 98.0 \n",
      "\n",
      "TESTING WITH NYANYA-MARARABA DATASET WHERE THERE IS NO WDN\n",
      "TESTING DATA\n",
      "MAE =  1329.5509909406328\n",
      "RMSE =  1488.2855641630592\n",
      "Rsquared = 53.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Read the file\n",
    "data = pd.read_csv(\"karu_data2.csv\")\n",
    "\n",
    "# Modeling with Selected Features\n",
    "X = data.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "y = data['Volume']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "\n",
    "#Modeling with Support Vector Regressor\n",
    "#model = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "model = Pipeline([('scaler', StandardScaler()), ('svr', LinearSVR(C=1.0, epsilon=0.2))])\n",
    "\n",
    "#Fitting the model\n",
    "SVR_Model = model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Testing the MLP code\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)\n",
    "\n",
    "#Testing model with Nyanya_Mararaba_dataset\n",
    "data2 = pd.read_csv(\"Nyanya_Mararaba_test2.csv\")\n",
    "\n",
    "# Modeling with Predictor Features\n",
    "X2 = data2.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "# Target Feature\n",
    "y2 = data2['Volume']\n",
    "\n",
    "#Testing with Nyanya_Marataba_dataset\n",
    "print(\"TESTING WITH NYANYA-MARARABA DATASET WHERE THERE IS NO WDN\")\n",
    "testing(X2, y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelling Support Vector Regression with Nyanya_Mararaba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "MAE =  93.51842773575494\n",
      "RMSE =  126.0159537034477\n",
      "Rsquared = 52.0 \n",
      "\n",
      "VALIDATION DATA\n",
      "MAE =  81.99190230973717\n",
      "RMSE =  110.7623908408303\n",
      "Rsquared = 54.0 \n",
      "\n",
      "TESTING DATA\n",
      "MAE =  102.33170867013213\n",
      "RMSE =  128.22813298583634\n",
      "Rsquared = 58.0 \n",
      "\n",
      "COMPLETE DATA\n",
      "MAE =  93.24710328659094\n",
      "RMSE =  124.80021074346257\n",
      "Rsquared = 53.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file\n",
    "data = pd.read_csv(\"Nyanya_Mararaba_test2.csv\")\n",
    "\n",
    "# Modeling with Selected Features\n",
    "X = data.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "y = data['Volume']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelling Multilayer Perceptron ANN with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "MAE =  37.7952004252488\n",
      "RMSE =  96.51036510309063\n",
      "Rsquared = 98.0 \n",
      "\n",
      "VALIDATION DATA\n",
      "MAE =  35.10788581752829\n",
      "RMSE =  92.91735217378621\n",
      "Rsquared = 98.0 \n",
      "\n",
      "TESTING DATA\n",
      "MAE =  28.027534148417498\n",
      "RMSE =  61.23991515718835\n",
      "Rsquared = 99.0 \n",
      "\n",
      "COMPLETE DATA\n",
      "MAE =  36.54970233679362\n",
      "RMSE =  93.21907858485943\n",
      "Rsquared = 98.0 \n",
      "\n",
      "TRAINING WITH NORMAL EQUATION\n",
      "Here are the parameters; intercept is first in the list:  \n",
      " [ 9.20546098e+01  8.72676912e-01  1.58182685e-02 -1.27003886e+00\n",
      "  8.78830959e+00] \n",
      "\n",
      "MAE =  35.16629932028874\n",
      "RMSE =  96.83074255909101\n",
      "Rsquared = 97.0 \n",
      "\n",
      "VALIDATING WITH NORMAL EQUATION\n",
      "Here are the parameters; intercept is first in the list:  \n",
      " [-3.05062676e+02  6.77661874e+00 -6.97215057e-02  2.12127544e+00\n",
      "  8.84334860e+00] \n",
      "\n",
      "MAE =  35.52609965307019\n",
      "RMSE =  90.27756440394964\n",
      "Rsquared = 98.0 \n",
      "\n",
      "TESTING WITH NORMAL EQUATION\n",
      "Here are the parameters; intercept is first in the list:  \n",
      " [-1.52131279e+02  1.58167778e+00 -4.73988945e-02  1.53031464e+00\n",
      "  9.10457869e+00] \n",
      "\n",
      "MAE =  13.104394551850726\n",
      "RMSE =  54.983074103350404\n",
      "Rsquared = 99.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read the file\n",
    "data = pd.read_csv(\"karu_data2.csv\")\n",
    "\n",
    "# Modeling with Selected Features\n",
    "X = data.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "y = data['Volume']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "model = Pipeline([('scaler', StandardScaler()), ('sgd', MLPRegressor(hidden_layer_sizes=(32,),\n",
    "                   activation=\"relu\", \n",
    "                   solver='adam',\n",
    "                   learning_rate_init=0.1,\n",
    "                   random_state=1, \n",
    "                   warm_start=True,\n",
    "                   max_iter=2000))])\n",
    "   \n",
    "# Fitting the model\n",
    "ANN_Model = model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the MLP code\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)\n",
    "\n",
    "#Calling Normal Equation\n",
    "print(\"TRAINING WITH NORMAL EQUATION\")\n",
    "normal_equation(X_train, y_train)\n",
    "print(\"VALIDATING WITH NORMAL EQUATION\")\n",
    "normal_equation(X_valid, y_valid)\n",
    "print(\"TESTING WITH NORMAL EQUATION\")\n",
    "normal_equation(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Multilayer Perceptron ANN with Nyanya_Mararaba_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "MAE =  75.99743735239618\n",
      "RMSE =  96.70147637670564\n",
      "Rsquared = 64.0 \n",
      "\n",
      "VALIDATION DATA\n",
      "MAE =  72.14901531706879\n",
      "RMSE =  100.78081141568599\n",
      "Rsquared = 53.0 \n",
      "\n",
      "TESTING DATA\n",
      "MAE =  78.67229576020421\n",
      "RMSE =  101.13567977220255\n",
      "Rsquared = 63.0 \n",
      "\n",
      "COMPLETE DATA\n",
      "MAE =  75.8800809896442\n",
      "RMSE =  97.56772106596827\n",
      "Rsquared = 63.0 \n",
      "\n",
      "TRAINING WITH NORMAL EQUATION\n",
      "Here are the parameters; intercept is first in the list:  \n",
      " [-5.47561994e+02  1.28519662e+01  3.75884477e-03  3.24735030e+00\n",
      "  8.27053745e-01] \n",
      "\n",
      "MAE =  86.71148593746958\n",
      "RMSE =  109.60446859673384\n",
      "Rsquared = 54.0 \n",
      "\n",
      "VALIDATING WITH NORMAL EQUATION\n",
      "Here are the parameters; intercept is first in the list:  \n",
      " [71.74329864  9.7746765  -0.18060333 -3.40322325  0.8058308 ] \n",
      "\n",
      "MAE =  76.47310392102946\n",
      "RMSE =  103.22469880914628\n",
      "Rsquared = 49.0 \n",
      "\n",
      "TESTING WITH NORMAL EQUATION\n",
      "Here are the parameters; intercept is first in the list:  \n",
      " [-3.18971266e+01 -9.38036190e-01 -3.05890918e-02  1.96795568e+00\n",
      "  8.97940364e-01] \n",
      "\n",
      "MAE =  88.87245340224166\n",
      "RMSE =  113.39790551082157\n",
      "Rsquared = 53.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the file\n",
    "data = pd.read_csv(\"Nyanya_Mararaba_test2.csv\")\n",
    "\n",
    "# Modeling with Selected Features\n",
    "X = data.drop(columns=['ID',\n",
    "            'Volume'], axis=1)\n",
    "\n",
    "y = data['Volume']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "model = Pipeline([('scaler', StandardScaler()), ('sgd', MLPRegressor(hidden_layer_sizes=(32,),\n",
    "                   activation=\"relu\", \n",
    "                   solver='adam',\n",
    "                   learning_rate_init=0.1,\n",
    "                   random_state=1, \n",
    "                   warm_start=True,\n",
    "                   max_iter=2000))])\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)\n",
    "\n",
    "#Calling Normal Equation\n",
    "print(\"TRAINING WITH NORMAL EQUATION\")\n",
    "normal_equation(X_train, y_train)\n",
    "print(\"VALIDATING WITH NORMAL EQUATION\")\n",
    "normal_equation(X_valid, y_valid)\n",
    "print(\"TESTING WITH NORMAL EQUATION\")\n",
    "normal_equation(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "anaconda-2022.05-py39",
   "language": "python",
   "name": "conda-env-anaconda-2022.05-py39-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
