{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://githubtocolab.com/ANDREWTOLUTAIWO/poor_people_water_consumption/blob/main/PhD%20Thesis%20MLR%20code.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training, Validation, Testing, Prediction and Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "# Training the model\n",
    "def training(x1, y1):\n",
    "    print('TRAINING DATA')\n",
    "    X_train_prediction = model.predict(x1)\n",
    "    #Evaluating the trained model\n",
    "    evaluation(y_train, X_train_prediction)\n",
    "    \n",
    "#Validating the model\n",
    "def validation(x1, y1):\n",
    "    print('VALIDATION DATA')\n",
    "    X_valid_prediction = model.predict(x1)\n",
    "    #Evaluating the validated model\n",
    "    evaluation(y1, X_valid_prediction)\n",
    "\n",
    "#Testing the model\n",
    "def testing(x1, y1):\n",
    "    print('TESTING DATA')\n",
    "    X_test_prediction = model.predict(x1)\n",
    "    #Evaluating the tested model\n",
    "    evaluation(y1, X_test_prediction)\n",
    "    \n",
    "\n",
    "# Predicting with the complete data\n",
    "def complete_prediction(x1, y1):\n",
    "    print('COMPLETE DATA')\n",
    "    X_complete_prediction = model.predict(x1)\n",
    "    evaluation(y, X_complete_prediction)\n",
    "    #Convert to dataframe\n",
    "    pred = pd.DataFrame(X_complete_prediction, columns=['Predicted volume'])\n",
    "    # Join original data table and pred\n",
    "    complete_data = pd.DataFrame(pd.concat([data_new, pred], axis=1))\n",
    "    #Get first 100 records\n",
    "    data100_without_GSF = complete_data.iloc[:100]\n",
    "    #print into excel csv file\n",
    "    data100_without_GSF = data100_without_GSF.to_csv('data100_without_GSF.csv')\n",
    "    #Complete_Data_With_Prediction = complete_data.to_csv('poor_people_water_data_predicted_february.csv')\n",
    "    \n",
    "# Model evaluation with Mean Absolute Error, Root Mean Square Error and Rsquare Score\n",
    "def evaluation(x, y):\n",
    "    mae = np.abs(np.subtract(x, np.asarray(y))).mean()\n",
    "    print('Mean absolute error = ', mae)\n",
    "    rmse = math.sqrt(np.square(np.subtract(x, y)).mean())\n",
    "    print('Root mean square error = ', rmse)\n",
    "    n = (np.subtract(x, x.mean())*np.subtract(y, y.mean())).sum()\n",
    "    d = math.sqrt(np.square(np.subtract(x, x.mean())).sum()*np.square(np.subtract(y, y.mean())).sum())\n",
    "    r2s = np.square(n/d)\n",
    "    print('Rsquare score =', r2s, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pearson Correlation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pearson Correlation\n",
    "def pearson_correlation(data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    corr = data.corr()\n",
    "    #Plotting heatmap\n",
    "    plt.figure(figsize = (10,6))\n",
    "    return corr\n",
    "    #sns.heatmap(corr, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Household income</th>\n",
       "      <th>Household size</th>\n",
       "      <th>Travel time</th>\n",
       "      <th>Amount spent</th>\n",
       "      <th>Willingness to pay</th>\n",
       "      <th>Volume in lpcd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Household income</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333805</td>\n",
       "      <td>-0.118495</td>\n",
       "      <td>0.159673</td>\n",
       "      <td>0.165434</td>\n",
       "      <td>0.147813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Household size</th>\n",
       "      <td>0.333805</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.189469</td>\n",
       "      <td>-0.261648</td>\n",
       "      <td>-0.116366</td>\n",
       "      <td>-0.298999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Travel time</th>\n",
       "      <td>-0.118495</td>\n",
       "      <td>0.189469</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.707457</td>\n",
       "      <td>-0.686565</td>\n",
       "      <td>-0.851267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amount spent</th>\n",
       "      <td>0.159673</td>\n",
       "      <td>-0.261648</td>\n",
       "      <td>-0.707457</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.775729</td>\n",
       "      <td>0.903938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Willingness to pay</th>\n",
       "      <td>0.165434</td>\n",
       "      <td>-0.116366</td>\n",
       "      <td>-0.686565</td>\n",
       "      <td>0.775729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.690710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Volume in lpcd</th>\n",
       "      <td>0.147813</td>\n",
       "      <td>-0.298999</td>\n",
       "      <td>-0.851267</td>\n",
       "      <td>0.903938</td>\n",
       "      <td>0.690710</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Household income  Household size  Travel time  \\\n",
       "Household income            1.000000        0.333805    -0.118495   \n",
       "Household size              0.333805        1.000000     0.189469   \n",
       "Travel time                -0.118495        0.189469     1.000000   \n",
       "Amount spent                0.159673       -0.261648    -0.707457   \n",
       "Willingness to pay          0.165434       -0.116366    -0.686565   \n",
       "Volume in lpcd              0.147813       -0.298999    -0.851267   \n",
       "\n",
       "                    Amount spent  Willingness to pay  Volume in lpcd  \n",
       "Household income        0.159673            0.165434        0.147813  \n",
       "Household size         -0.261648           -0.116366       -0.298999  \n",
       "Travel time            -0.707457           -0.686565       -0.851267  \n",
       "Amount spent            1.000000            0.775729        0.903938  \n",
       "Willingness to pay      0.775729            1.000000        0.690710  \n",
       "Volume in lpcd          0.903938            0.690710        1.000000  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# One-Hot Encoding\n",
    "data = pd.read_csv(\"dry_season_data_without_GSF.csv\")\n",
    "\n",
    "encoded_data = pd.get_dummies(data, columns = ['Gender', 'Method', 'Availability', 'Quality'])\n",
    "\n",
    "data_new = pd.DataFrame(encoded_data)\n",
    "\n",
    "data_pearson = data_new.drop(columns=['ID', \n",
    "            'Education',\n",
    "            'Rainfall',\n",
    "            'Ave temp',\n",
    "            'Kitchen Sink',\n",
    "            'ToiletWC',\n",
    "            'Garden',\n",
    "            'Car',\n",
    "            'Gender_male',\n",
    "            'Gender_female',\n",
    "            'Method_delivered',\n",
    "            'Method_borehole',\n",
    "            'Method_carried',\n",
    "            'Method_well',\n",
    "            'Availability_not_often',\n",
    "            'Availability_often',\n",
    "            'Quality_poor',\n",
    "            'Quality_fair',\n",
    "            'Quality_good',\n",
    "            'Quality_very good'], axis=1)\n",
    "\n",
    "# Testing the feature selection code\n",
    "pearson_correlation(data_pearson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Multilinear Regression with Selected Featuers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Mean absolute error =  7.255551449773989\n",
      "Root mean square error =  11.390650558960186\n",
      "Rsquare score = 0.9183084394125011 \n",
      "\n",
      "VALIDATION DATA\n",
      "Mean absolute error =  6.922964534894492\n",
      "Root mean square error =  8.868308816056931\n",
      "Rsquare score = 0.9430175649288389 \n",
      "\n",
      "TESTING DATA\n",
      "Mean absolute error =  6.586496212488465\n",
      "Root mean square error =  9.223483205704737\n",
      "Rsquare score = 0.9367061631421686 \n",
      "\n",
      "COMPLETE DATA\n",
      "Mean absolute error =  7.155387234557482\n",
      "Root mean square error =  10.962184567656157\n",
      "Rsquare score = 0.9220759905312288 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "# One-Hot Encoding\n",
    "data = pd.read_csv(\"dry_season_data_without_GSF.csv\")\n",
    "\n",
    "encoded_data = pd.get_dummies(data, columns = ['Gender', 'Method', 'Availability', 'Quality'])\n",
    "\n",
    "data_new = pd.DataFrame(encoded_data)\n",
    "# Modeling with Selected Features\n",
    "X = data_new.drop(columns=['ID',\n",
    "            'Household income',\n",
    "            'Education',\n",
    "            'Rainfall',\n",
    "            'Kitchen Sink',\n",
    "            'ToiletWC',\n",
    "            'Garden',\n",
    "            'Car',\n",
    "            'Volume in lpcd',\n",
    "            'Gender_male',\n",
    "            'Gender_female',\n",
    "            'Method_delivered',\n",
    "            'Availability_not_often',\n",
    "            'Availability_often',\n",
    "            'Quality_fair',\n",
    "            'Quality_good',\n",
    "            'Quality_very good'], axis=1)\n",
    "\n",
    "y = data_new['Volume in lpcd']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "# Developing the model with Pipeline that infuses StandardScaler with SDGRegressor\n",
    "model = Pipeline([('scaler', StandardScaler()), ('sgd', SGDRegressor(max_iter=10000, tol=1e-3))])\n",
    "\n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "#Testing the MLR code\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling Random  Forest with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out of bag score =  0.9641282693319799 \n",
      "\n",
      "TRAINING DATA\n",
      "Mean absolute error =  2.2552474529815063\n",
      "Root mean square error =  4.987680612392865\n",
      "Rsquare score = 0.9843639741912371 \n",
      "\n",
      "VALIDATION DATA\n",
      "Mean absolute error =  2.616031648406002\n",
      "Root mean square error =  5.214332996431043\n",
      "Rsquare score = 0.9805448659728101 \n",
      "\n",
      "TESTING DATA\n",
      "Mean absolute error =  2.33876124976671\n",
      "Root mean square error =  4.35998846102998\n",
      "Rsquare score = 0.9862913723628463 \n",
      "\n",
      "COMPLETE DATA\n",
      "Mean absolute error =  2.2996772522024607\n",
      "Root mean square error =  4.951913075851612\n",
      "Rsquare score = 0.984219521750785 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# One-Hot Encoding\n",
    "data = pd.read_csv(\"dry_season_data_without_GSF.csv\")\n",
    "\n",
    "encoded_data = pd.get_dummies(data, columns = ['Gender', 'Method', 'Availability', 'Quality'])\n",
    "\n",
    "data_new = pd.DataFrame(encoded_data)\n",
    "# Modeling with Selected Features\n",
    "X = data_new.drop(columns=['ID',\n",
    "            'Household income',\n",
    "            'Education',\n",
    "            'Rainfall',\n",
    "            'Kitchen Sink',\n",
    "            'ToiletWC',\n",
    "            'Garden',\n",
    "            'Car',\n",
    "            'Volume in lpcd',\n",
    "            'Gender_male',\n",
    "            'Gender_female',\n",
    "            'Method_delivered',\n",
    "            'Availability_not_often',\n",
    "            'Availability_often',\n",
    "            'Quality_fair',\n",
    "            'Quality_good',\n",
    "            'Quality_very good'], axis=1)\n",
    "\n",
    "y = data_new['Volume in lpcd']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "#Modeling with Random Forest Regressor\n",
    "model = RandomForestRegressor(random_state=42, n_jobs=-1, max_depth=5,\n",
    "                                       n_estimators=100, oob_score=True)\n",
    "\n",
    "#Fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# checking the oob score\n",
    "print('Out of bag score = ', model.oob_score_, '\\n')\n",
    "\n",
    "\n",
    "# Testing the MLP code\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Support Vector Regression with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Mean absolute error =  6.31192675666225\n",
      "Root mean square error =  13.21990846129287\n",
      "Rsquare score = 0.8893282859008069 \n",
      "\n",
      "VALIDATION DATA\n",
      "Mean absolute error =  4.927546638894555\n",
      "Root mean square error =  8.326081941937838\n",
      "Rsquare score = 0.9387860658989177 \n",
      "\n",
      "TESTING DATA\n",
      "Mean absolute error =  5.145149308476594\n",
      "Root mean square error =  10.546550345033229\n",
      "Rsquare score = 0.9341454163660883 \n",
      "\n",
      "COMPLETE DATA\n",
      "Mean absolute error =  6.056811000066896\n",
      "Root mean square error =  12.564558100004472\n",
      "Rsquare score = 0.8979543930125268 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# One-Hot Encoding\n",
    "data = pd.read_csv(\"dry_season_data_without_GSF.csv\")\n",
    "\n",
    "encoded_data = pd.get_dummies(data, columns = ['Gender', 'Method', 'Availability', 'Quality'])\n",
    "\n",
    "data_new = pd.DataFrame(encoded_data)\n",
    "# Modeling with Selected Features\n",
    "X = data_new.drop(columns=['ID',\n",
    "            'Household income',\n",
    "            'Education',\n",
    "            'Rainfall',\n",
    "            'Kitchen Sink',\n",
    "            'ToiletWC',\n",
    "            'Garden',\n",
    "            'Car',\n",
    "            'Volume in lpcd',\n",
    "            'Gender_male',\n",
    "            'Gender_female',\n",
    "            'Method_delivered',\n",
    "            'Availability_not_often',\n",
    "            'Availability_often',\n",
    "            'Quality_fair',\n",
    "            'Quality_good',\n",
    "            'Quality_very good'], axis=1)\n",
    "\n",
    "y = data_new['Volume in lpcd']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "\n",
    "#Modeling with Support Vector Regressor\n",
    "#model = make_pipeline(StandardScaler(), SVR(C=1.0, epsilon=0.2))\n",
    "model = Pipeline([('scaler', StandardScaler()), ('svr', LinearSVR(C=1.0, epsilon=0.2))])\n",
    "\n",
    "#Fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Testing the MLP code\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Modelling Multilayer Perceptron ANN with Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAINING DATA\n",
      "Mean absolute error =  4.87639974486996\n",
      "Root mean square error =  7.982866400097984\n",
      "Rsquare score = 0.9583919568429035 \n",
      "\n",
      "VALIDATION DATA\n",
      "Mean absolute error =  5.495508873261042\n",
      "Root mean square error =  7.2593522517766615\n",
      "Rsquare score = 0.9688061914235934 \n",
      "\n",
      "TESTING DATA\n",
      "Mean absolute error =  5.016408151768464\n",
      "Root mean square error =  8.262159676077832\n",
      "Rsquare score = 0.9582222896770582 \n",
      "\n",
      "COMPLETE DATA\n",
      "Mean absolute error =  4.95231149839893\n",
      "Root mean square error =  7.942107562372143\n",
      "Rsquare score = 0.9591918109556836 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# One-Hot Encoding\n",
    "data = pd.read_csv(\"dry_season_data_without_GSF.csv\")\n",
    "\n",
    "encoded_data = pd.get_dummies(data, columns = ['Gender', 'Method', 'Availability', 'Quality'])\n",
    "\n",
    "data_new = pd.DataFrame(encoded_data)\n",
    "# Modeling with Selected Features\n",
    "X = data_new.drop(columns=['ID',\n",
    "            'Household income',\n",
    "            'Education',\n",
    "            'Rainfall',\n",
    "            'Kitchen Sink',\n",
    "            'ToiletWC',\n",
    "            'Garden',\n",
    "            'Car',\n",
    "            'Volume in lpcd',\n",
    "            'Gender_male',\n",
    "            'Gender_female',\n",
    "            'Method_delivered',\n",
    "            'Availability_not_often',\n",
    "            'Availability_often',\n",
    "            'Quality_fair',\n",
    "            'Quality_good',\n",
    "            'Quality_very good'], axis=1)\n",
    "\n",
    "y = data_new['Volume in lpcd']\n",
    "\n",
    "# Splitting data_var into training-validation-test set in ratio 80-10-10\n",
    "# We first split the data into training and remaining dataset\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.8)\n",
    "\n",
    "# Now we divide the remaining data equally between valid and test\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem, y_rem, test_size=0.5)\n",
    "\n",
    "model = Pipeline([('scaler', StandardScaler()), ('sgd', MLPRegressor(hidden_layer_sizes=(32,),\n",
    "                   activation=\"relu\", \n",
    "                   solver='adam',\n",
    "                   learning_rate_init=0.01,\n",
    "                   random_state=1, \n",
    "                   warm_start=True,\n",
    "                   max_iter=2000))])\n",
    "   \n",
    "# Fitting the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Testing the MLP code\n",
    "training(X_train, y_train)\n",
    "validation(X_valid, y_valid)\n",
    "testing(X_test, y_test)\n",
    "complete_prediction(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "264px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
